
import sqlite3
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import streamlit as st
from langchain_openai import ChatOpenAI
from langchain_groq import ChatGroq
from langchain.schema import HumanMessage
from pydantic import BaseModel, Field
from typing import Optional, List, Dict, Any, Literal

from langchain.output_parsers import PydanticOutputParser
from langchain.schema.messages import HumanMessage

# Pydantic Models
class SQLQuery(BaseModel):
    """Structured SQL query output"""
    sql: str = Field(description="The SQL query to execute")
    explanation: str = Field(description="Brief explanation of what the query does")

class ChartMetadata(BaseModel):
    chart_type: Optional[Literal['bar', 'pie', 'line', 'scatter']]
    x_column: Optional[str]
    y_column: Optional[str]
    groupby_column: Optional[str]
    aggregation: Optional[str]
    reason: Optional[str]

class LLMResponse(BaseModel):
    text: str = Field(..., description="Mandatory textual explanation or answer")
    chart: Optional[ChartMetadata] = Field(None, description="If chart is helpful, metadata to create it; otherwise, null.")



# Create parser for your LLMResponse model
parser = PydanticOutputParser(pydantic_object=LLMResponse)



def get_llm(provider, api_key):
    if provider == "openai":
        return ChatOpenAI(model="gpt-4.1-nano", api_key=api_key)
    elif provider == "groq":
        return ChatGroq(model="llama3-8b-8192", api_key=api_key)

def get_db_schema_and_sample(conn, table_name="customer_data"):
    cursor = conn.cursor()
    cursor.execute(f"PRAGMA table_info({table_name})")
    schema_info = cursor.fetchall()
    columns = [(col[1], col[2]) for col in schema_info]  # (column_name, data_type)

    df_sample = pd.read_sql_query(f"SELECT * FROM {table_name} LIMIT 5", conn)
    return columns, df_sample

def generate_prompt(user_question, schema):
    schema_str = "\n".join(f"- {name}: {dtype}" for name, dtype in schema)
    return 


def execute_code(code: str, df_result: pd.DataFrame):
    """
    Execute python code string in a minimal environment with df_result, plt, pd, np available.
    Returns matplotlib Figure if created, or resulting DataFrame if table_code.
    """
    local_vars = {
        'df_result': df_result,
        'plt': plt,
        'pd': pd,
        'np': np,
        'fig': None,
        'result_table': None
    }

    plt.close('all')  # clear any previous figures

    try:
        exec(code, {}, local_vars)
        fig = local_vars.get('fig') or plt.gcf()
        result_table = local_vars.get('result_table')
        return fig, result_table
    except Exception as e:
        print(f"Code execution error: {e}")
        return None, None


def generate_structured_sql(llm, question, columns, df_sample, table_name="customer_data"):
    context = build_prompt_context(question, columns, df_sample, table_name)

    prompt = f"""
{context}

You are an AI that generates SQLite queries.

Return only the raw SQL query (no markdown, no explanation).
"""
    response = llm.invoke([HumanMessage(content=prompt)])
    sql_query = response.content.strip()
    
    return SQLQuery(sql=sql_query, explanation="Generated by LLM")


import re

def extract_sql(text):
    # Case 1: Pure SQL query with no extra text → return directly
    if text.strip().lower().startswith("select") or " from " in text.lower():
        return text.strip()
    
    # Case 2: Markdown-formatted SQL block
    match = re.search(r"```sql(.*?)```", text, re.DOTALL | re.IGNORECASE)
    if match:
        return match.group(1).strip()

    # Case 3: Strip narration like "Here is the query:"
    lines = text.strip().splitlines()
    clean_lines = [
        line for line in lines
        if not line.strip().lower().startswith("here") and not line.strip().startswith("```")
    ]
    return "\n".join(clean_lines).strip()


def execute_sql_query(conn, sql_query):
    try:
        sql_query = sql_query.strip()
        sql_query=extract_sql(sql_query)
        df_result = pd.read_sql_query(sql_query, conn)
        return df_result, None
    except Exception as e:
        error_msg = f"SQL Error: {str(e)}\nGenerated SQL: {sql_query}"
        return None, error_msg


def llm_needs_sql(llm, question, columns, df_sample, table_name="customer_data"):
    context = build_prompt_context(question, columns, df_sample, table_name)

    prompt = f"""
{context}

You are deciding whether a user's question requires a SQL query.

If SQL is NOT needed, answer the user's question directly based on the schema and sample data provided. If SQL IS needed, just say "yes".
If the user's question involves calculations, aggregations, grouping, filtering, or any kind of summary/statistical analysis—even if sample data is provided—SQL is required.

Examples:
Q: "What is the total revenue per category?" → yes  
Q: "Summarize the table" → yes  
Q: "What is a DataFrame?" → no | "A DataFrame is a tabular data structure..."  
Q: "List last few things I asked" → no  
Q: "What is the data about?" → no | "The data contains customer bank activity and churn information."  
Q: "What is the SQL syntax for inner join?" → no
Q: "Show me the average age and credit score by country and gender." → yes  
Q: "Provide a chart of churn rate by country." → yes  
Q: "Plot the distribution of account balances." → yes 

Now answer for:
Q: "{question}"

Reply with "yes" if SQL is needed.  
If not, reply with "no | <direct answer here>".
"""

    result = llm.invoke([HumanMessage(content=prompt)])
    output = result.content.strip()
    if output.lower().startswith("yes"):
        return True, ""
    elif output.lower().startswith("no"):
        # Extract the answer if present after the pipe symbol
        parts = output.split('|', 1)
        answer = parts[1].strip() if len(parts) > 1 else ""
        return False, answer
    else:
        # Fallback: assume SQL needed if unclear
        return True, ""

def build_prompt_context(question, columns, df_sample, table_name="customer_data"):
    schema_str = "\n".join([f"{name}: {dtype}" for name, dtype in columns])
    sample_str = df_sample.head(50).to_markdown(index=False)

    # Detailed column descriptions for accurate SQL generation
    column_details = """
Column Details:
- customer_id: Unique integer identifier for each customer (Primary Key, e.g., 15634602). Not used for analytics, mainly for identification.
- credit_score: Customer's credit score (integer, typically 300-850). Indicates creditworthiness.
- country: Country where the customer resides (categorical: France, Spain, Germany). Useful for regional segmentation.
- gender: Customer's gender (categorical: Male, Female).
- age: Customer's age in years (integer, e.g., 42). Numeric, suitable for range queries, aggregation, and segmentation.
- tenure: Number of years the customer has been with the bank (integer, 0-10). Useful for loyalty/retention analytics.
- balance: Account balance (float, can be 0, e.g., 159660.8). Represents the money in the customer's account.
- products_number: Number of bank products held by the customer (integer, e.g., 1-4). Useful for understanding customer engagement.
- credit_card: Whether the customer has a credit card (binary: 1 = Yes, 0 = No).
- active_member: Whether the customer is an active member (binary: 1 = Yes, 0 = No).
- estimated_salary: Estimated annual salary of the customer (float, e.g., 101348.88). Useful for income-based segmentation.
- churn: Target column. Indicates if the customer has left the bank (1 = Yes, 0 = No). Use this for churn prediction, not as a filter for retained customers unless explicitly asked.

Notes:
- Some numeric fields may be stored as TEXT. Use `CAST(column AS INTEGER/REAL)` as needed in SQL.
- 'churn' is the label column; all others are features or context for analysis.
"""

    return f"""
You are working with a SQLite table.

Table name: {table_name}

Schema:
{schema_str}

{column_details}

Sample Data (first 50 rows):
{sample_str}

User question: "{question}"
"""

def build_prompt(question: str, df_markdown: str, columns: list, parser) -> str:
    allowed_charts = ['bar', 'pie', 'line', 'scatter']
    format_instructions = parser.get_format_instructions()
    column_str = ", ".join(columns)

    return f"""
You are a data analyst. A user has a question about the following dataset.

Data:
{df_markdown}

User Question:
{question}

Your answer **must always include** a clear and concise explanation in the 'text' field.

If a chart will make the answer clearer, set the 'chart' field to a JSON object with:
- chart_type: one of {allowed_charts}
- x_column: (column name for x-axis, or null)
- y_column: (column name for y-axis, or null)
- groupby_column: (column to group by if needed, or null)
- aggregation: (mean, sum, count, etc, or null)
- reason: (why this chart helps the answer)

If no chart is needed, set 'chart' to null.

{format_instructions}

Columns in the data are: {column_str}
"""

def plot_chart(df, chart_metadata: ChartMetadata):
    if not chart_metadata or not chart_metadata.chart_type:
        return None  # No chart requested

    chart_type = chart_metadata.chart_type
    x = chart_metadata.x_column
    y = chart_metadata.y_column

    fig, ax = plt.subplots()
    if chart_type == 'pie':
        if x and y:
            # x should be labels, y should be values (already aggregated)
            data = df.set_index(x)[y]
            data.plot.pie(autopct='%1.1f%%', ax=ax)
            ax.set_ylabel('')
            ax.set_title(f"{y.replace('_', ' ').title()} by {x.replace('_', ' ').title()}")
        else:
            raise ValueError("Pie chart needs x_column and y_column.")
    elif chart_type == 'bar':
        if x and y:
            df.plot(x=x, y=y, kind='bar', ax=ax, legend=False)
            ax.set_xlabel(x.replace('_', ' ').title())
            ax.set_ylabel(y.replace('_', ' ').title())
            ax.set_title(f"{y.replace('_', ' ').title()} by {x.replace('_', ' ').title()}")
            ax.set_xticklabels(df[x], rotation=0)
        else:
            raise ValueError("Bar chart needs x_column and y_column.")
    elif chart_type == 'line':
        if x and y:
            df.plot(x=x, y=y, kind='line', ax=ax, legend=False)
            ax.set_xlabel(x.replace('_', ' ').title())
            ax.set_ylabel(y.replace('_', ' ').title())
            ax.set_title(f"{y.replace('_', ' ').title()} by {x.replace('_', ' ').title()}")
        else:
            raise ValueError("Line chart needs x_column and y_column.")
    elif chart_type == 'scatter':
        if x and y:
            df.plot.scatter(x=x, y=y, ax=ax)
            ax.set_xlabel(x.replace('_', ' ').title())
            ax.set_ylabel(y.replace('_', ' ').title())
            ax.set_title(f"{y.replace('_', ' ').title()} vs {x.replace('_', ' ').title()}")
        else:
            raise ValueError("Scatter plot needs x_column and y_column.")
    else:
        raise ValueError(f"Unsupported chart type: {chart_type}")

    plt.tight_layout()
    return fig



def analyze_data_with_llm(llm, question, df_result, parser, columns):
    df_markdown = df_result.to_markdown(index=False)
    prompt = build_prompt(question, df_markdown, columns, parser)

    response = llm.invoke([HumanMessage(content=prompt)])
    parsed = parser.parse(response.content)
    return parsed


#main caller function
def run_llm_data_flow(conn, question, llm, table_name="customer_data", parser=parser):

    # Step 1: Get database schema
    columns, df_sample = get_db_schema_and_sample(conn, table_name=table_name)
    print("fetching schema sucessful")

    # needs_sql = llm_needs_sql(llm, question, columns, df_sample, table_name)
    needs_sql, answer = llm_needs_sql(llm, question, columns, df_sample, table_name)
    if not needs_sql:
        print("No sql needed")
        response_dict = {"text": answer}
        dummy_df = None
        return dummy_df, response_dict
    print("SQL needed")
    
    # Step 2: Generate SQL query using LLM
    sql_query_obj = generate_structured_sql(llm, question, columns, df_sample, table_name=table_name)
    print(f"generated SQL query\n{sql_query_obj.sql}")
    # Step 3: Execute SQL to get data
    df_result, error = execute_sql_query(conn, sql_query_obj.sql)
    if error:
        print(f"error occured,\n{error} ")
        return None, {"type": "error", "error": error}

    # Step 4: Send data + user question to LLM for final analysis
    column_names = [c[0] for c in columns]
    final_result = analyze_data_with_llm(llm, question, df_result, parser, column_names)
    response_dict = {"text": final_result.text}
    print(final_result.text)
    if final_result.chart:
        print(final_result.chart)
        fig = plot_chart(df_result, final_result.chart)
        if fig:
            response_dict["plot_figure"] = fig

    return df_result, response_dict
